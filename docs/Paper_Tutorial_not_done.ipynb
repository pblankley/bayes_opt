{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Tutorial\n",
    "\n",
    "This tutorial uses bayesian optimization techniques to find the minimum of a function $ f ( x )$ on some bounded set $ X $ , on a subset of $ { R } ^ { D }$. The use of Bayesian optimization allows one to construct a probabilistic model for $ f ( x ) $ and then use this model to identify where in $ X $ to next evaluate the function. \n",
    "\n",
    "Typical use cases include when trying to find the minimum of a function, when evaluations of $ f ( x )$ are expensive to perform (for example, training machine learning models). This is done by optimizing where to evaluate next, so that the evaluation may be completed with relatively few evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes \n",
    "\n",
    "The user would like to find the minimum of difficult non-convex function. First, a series of Gaussian Processes (GPs) are drawn to put a probability distribution over the function. The prior distribution is modeled as a sample from a Gaussian process(GP). \n",
    "\n",
    "#### Why use Gaussian Processes?\n",
    "The GP finds a distribution over the possible functions $ f(x) $. A GP defines a prior over functions, which can be converted into a posterior over functions given data. GPs are frequently used because of their ability to toggle the smoothness as a hyper-parameter through the kernal function applied to the observed $ X $ values, or the covariance matrix. The covariance matrix to ensures that values that are close together in input space will produce output values that are close together. In other words, the GP will consider the smoothness before suggesting points too far away from the other. \n",
    "\n",
    "#### What hyperparameters should be used? \n",
    "While it is usually an advantage of GPs to be able to toggle the smoothness, this would require chosing a kernal and hyperparameters. The default kernal is the automatic relevance determination (ARD) squared exponential kernel, shown below: \n",
    "$$K _ { S E } ( \\mathbf { x } ,\\mathbf { x ^ { \\prime } } ) = \\theta _ { 0} \\exp \\left\\{ - \\frac { 1} { 2} r ^ { 2} ( \\mathbf { x } ,\\mathbf { x ^ { \\prime } } ) \\right\\} $$\n",
    "\n",
    "$$r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) = \\sum _ { d = 1} ^ { D } \\left( x _ { d } - x _ { d } ^ { \\prime } \\right) ^ { 2} / \\theta _ { d } ^ { 2}$$\n",
    "\n",
    "However, this is unrealistically smooth for practical optimization problems. Snoek et al. instead propose the use of the ARD Matern 5/2 kernel:\n",
    "\n",
    "$$K _ { M 52} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) = \\theta _ { 0} \\left( 1+ \\sqrt { 5r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) } + \\frac { 5} { 3} r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) \\right) \\exp \\left\\{ - \\sqrt { 5r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) } \\right\\}$$\n",
    "\n",
    "####  paul this makes no sense to me:  (about the eqn above). Can I cut?\n",
    "\"This covariance function results in sample functions which are twice-differentiable, an assumption that corresponds to those made by, e.g., quasi-Newton methods, but without requiring the smoothness of the squared exponential\"\n",
    "\n",
    "http://ml.dcs.shef.ac.uk/gpss/gpws14/KernelDesign.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition Function\n",
    "\n",
    "Once sampling functions with GPs, this prior and these data induce a posterior over functions. The GP has proposed several different functions. Now, where these functions are proposed dictates the the acquisition function. The acquisition function ($a : \\mathcal { X } \\rightarrow \\mathbb { R } ^ { + }$) determines what point in X should be evaluated next via a proxy optimization ($\\mathbf { X } _ { n e x t } = \\arg \\max _ { x } a ( x )$), given by the GPs proposals. \n",
    "\n",
    "Though three different acquisition functions are proposed, this tutorial focuses on the Expected Improvement (EI) criterion: \n",
    " \n",
    "$$ a _ { E l } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) = \\sigma \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) ( \\gamma ( \\mathbf { x } ) \\Phi ( \\gamma ( \\mathbf { x } ) ) + \\mathcal { N } ( \\gamma ( \\mathbf { x } ) ; 0,1) )$$\n",
    "\n",
    "Snoek et al. chose to maximize the expected improvement (EI) over the current best when chosing the next location to evaluate. \n",
    "\n",
    "# ( Paul - little confused here feel free to edit/)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"######################\" \n",
    "# Paul: New Text here\n",
    "\n",
    "To select where to observe the function next, one uses an acquisition function. \n",
    "\n",
    "The acquisition function is a function that can evaluate an expected loss associated with evaluating $f$ at a point $x$. The acquisition function is then optimized to select the location of the next observation. \n",
    "\n",
    "Snoek et al evaluate 3 possible acquisition functions, as described below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Improvement  \n",
    "\n",
    "The Probability of Improvement is proposed as the first acquisition function designed for Bayesian optimization. It maximizes the probability of improving over the best current value. Under the GP this can be computed analytically as\n",
    "\n",
    "$a _ { P l } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) = \\Phi ( \\gamma ( \\mathbf { x } ) )$ , $\\gamma ( \\mathbf { x } ) = \\frac { f \\left( \\mathbf { x } _ { \\text{best} } \\right) - \\mu \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) } { \\sigma \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) }$\n",
    "\n",
    "However, the loss function associated with probability of improvement does not take into account the size of the improvement. Practically, Probability of Improvement can get stuck in local optima and underexplore globally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Improvemet\n",
    "\n",
    "An alternative acquisition function that does account for the size of the improvement is expected\n",
    "improvement (EI). The algorithm maximizes the expected improvement (EI) over the current best. This also has closed form under the Gaussian process:\n",
    "\n",
    "$$ a _ { E l } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) = \\sigma \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) ( \\gamma ( \\mathbf { x } ) \\Phi ( \\gamma ( \\mathbf { x } ) ) + \\mathcal { N } ( \\gamma ( \\mathbf { x } ) ; 0,1) )$$\n",
    "\n",
    "Although the EI includes an encoding a tradeoff between exploitation (evaluating at points with low mean) and exploration (evaluating at points with high uncertainty), this tradeoff is a common consideration. \n",
    "\n",
    "Snoek et al. chose to maximize the expected improvement (EI) over the current best when chosing the next location to evaluate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Upper Confidence Bound \n",
    "A final proposed acquisition function is derived from the GP Upper Confidence Bounds. This process exploits (higher, or lower) confidence bounds to construct acquisition functions that minimize regret over the course of optimization. These acquisition functions have the form:\n",
    "\n",
    "\n",
    "$a _ { L C B } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { X } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) =$\n",
    "$\\mu \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) - \\kappa \\sigma \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right)$\n",
    "\n",
    "# \"##################################\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For our problems of interest, typically\n",
    "we would have $D$ + 3 Gaussian process hyperparameters: $D$ length scales $\\theta _ { 1} : D$, the covariance\n",
    "amplitude $\\theta _ { 0}$, the observation noise $\\mathcal { V }$, and a constant mean $ m$. The most commonly advocated approach\n",
    "is to use a point estimate of these parameters by optimizing the marginal likelihood under the\n",
    "Gaussian process, $p \\left( \\mathbf { y } | \\left\\{ \\mathbf { x } _ { n } \\right\\} _ { n = 1} ^ { N } ,\\theta ,\\nu ,\\dot { m } \\right) = \\mathcal { N } \\left( \\mathbf { y } | \\mathbf { m } \\mathbf { 1} ,\\mathbf { \\Sigma } _ { \\theta } + \\nu \\mathbf { I } \\right)$\n",
    "and Σθ is the covariance matrix resulting from the N input points under the hyperparameters θ.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "However, for a fully-Bayesian treatment of hyperparameters (summarized here by $ \\theta$ alone), it is\n",
    "desirable to marginalize over hyperparameters and compute the integrated acquisition function:\n",
    "\n",
    "$$\\hat { a } \\left( \\mathbf { X } ; \\left\\{ \\mathbf { X } _ { n } ,y _ { n } \\right\\} \\right) = $$\n",
    "$$ \\int a \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta \\right) p \\left( \\theta | \\left\\{ \\mathbf { X } _ { n } ,y _ { n } \\right\\} _ { n = 1} ^ { N } \\right) d \\theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $ a ( x )$  depends on $\\theta$ and all of the observations. For probability of improvement and EI, this\n",
    "expectation is the correct generalization to account for uncertainty in hyperparameters. We can\n",
    "therefore blend acquisition functions arising from samples from the posterior over GP hyperparameters\n",
    "and have a Monte Carlo estimate of the integrated expected improvement.a ( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"#######################################################\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC \n",
    "\n",
    "This method allows the user to parallelize optimization procedures. Snoek et al compute Monte Carlo estimates of the acquisiton function under different possible results from pending function evaluations. This allows the algorithm to identify what $X$ should be evaluated next, even while a set of points are currently being evaluated (parallelized).\n",
    "\n",
    "This is done as the same acquisition function cannot be used again, or a pending experiment would repeate and thus waste computing resources (cost, time, etc). \n",
    "\n",
    "A new point is proposed to be evaluated next based on the expected acquisition function under all possible outcomes of these pending evaluations:\n",
    "\n",
    "$$\\hat { a } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta ,\\left\\{ \\mathbf { x } _ { j } \\right\\} \\right) =$$ \n",
    "$$\\int _ { \\mathbb { R } ^ { J } } a \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta ,\\left\\{ \\mathbf { x } _ { j } ,y _ { j } \\right\\} \\right) p \\left( \\left\\{ y _ { j } \\right\\} _ { j = 1} ^ { J } | \\left\\{ \\mathbf { x } _ { j } \\right\\} _ { j = 1} ^ { J } ,\\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} _ { n = 1} ^ { N } \\right) \\text{d} y _ { 1} \\cdots \\text{d} y _ { J }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I ignored modeling costs- shall I put it back in?)\n",
    "\n",
    "We would like to be able to decide what x should be evaluated next, even while a set of points are being evaluated.\n",
    "\n",
    "We propose a sequential strategy that takes advantage of the tractable inference properties of the Gaussian process to compute Monte Carlo estimates of the acquisiton function under different possible results from pending function evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## should I cut this eqn\n",
    "\n",
    "$$\\hat { a } \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta ,\\left\\{ \\mathbf { x } _ { j } \\right\\} \\right) =$$\n",
    "$$ \\int _ { \\mathbb { R } ^ { J } } a \\left( \\mathbf { x } ; \\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} ,\\theta ,\\left\\{ \\mathbf { x } _ { j } ,y _ { j } \\right\\} \\right) p \\left( \\left\\{ y _ { j } \\right\\} _ { j = 1} ^ { J } | \\left\\{ \\mathbf { x } _ { j } \\right\\} _ { j = 1} ^ { J } ,\\left\\{ \\mathbf { x } _ { n } ,y _ { n } \\right\\} _ { n = 1} ^ { N } \\right) \\text{d} y _ { 1} \\cdots \\text{d} y _ { J } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paper Tutorial\n",
    "\n",
    "This tutorial uses bayesian optimization techniques to find the minimum of a function $ f ( x )$ on some bounded set $ X $ , on a subset of $ { R } ^ { D }$. The use of Bayesian optimization allows one to construct a probabilistic model for $ f ( x ) $ and then use this model to identify where in $ X $ to next evaluate the function. \n",
    "\n",
    "Typical use cases include when trying to find the minimum of a function, when evaluations of $ f ( x )$ are expensive to perform (for example, training machine learning models). This is done by optimizing where to evaluate next. \n",
    "\n",
    "\"This results in a procedure that can find the minimum of difficult non-convex functions with relatively few evaluations, at the cost of performing more computation to determine the next point to try. When evaluations of f(x) are expensive to perform — as is the case when it requires training a machine learning algorithm — then it is easy to justify some extra computation to make better decision\"\n",
    "\n",
    "\n",
    "The tutorial provides \"automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-770b1d8a65f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-770b1d8a65f3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sources: http://katbailey.github.io/post/gaussian-processes-for-dummies/\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sources: http://katbailey.github.io/post/gaussian-processes-for-dummies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The tutorial provides \"automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is usually an advantage of GPs to be able to toggle the smoothness, a typical kernal is the automatic relevance determination (ARD) squared exponential kernel. This is unrealistically smooth for practical optimization problems. \n",
    "Snoek instead proposes the use of the ARD Matern ´ 5/2 kernel:\n",
    "\n",
    "$$K _ { M 52} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) = \\theta _ { 0} \\left( 1+ \\sqrt { 5r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) } + \\frac { 5} { 3} r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) \\right) \\exp \\left\\{ - \\sqrt { 5r ^ { 2} \\left( \\mathbf { x } ,\\mathbf { x } ^ { \\prime } \\right) } \\right\\}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
